============================================================================
	HYPERION ENGINE
	Notes - Threading Changes
============================================================================

* Were going to be making some very big changes to the engine, by going from a primarily two-threaded design, to a full, multi-threaded design, making use of all system cores
* The first thing we have to do, is some git-hub work, we need to make a seperate branch.
* Created Branch: multi-threading

* Now, we need to working on the task pool, unfortunatley, the engine is not buildable. Maybe, we should get it to a buildable state so we can run tests.
* With our new task pool, do we need a wait any function? Or just wait all?
* Lets figure out how we want to use the task pool first...

----------------------------- New Task Pool System ---------------------------------

* No matter what, were going to need some locking to ensure worker threads can aquire work, the only alternative is so use a busy wait.
* Although, busy waiting would give us the desired result (low latency), it would waste CPU cycles we could use for some other task.
* We can use a combination of both, to allow for higher performance without excessive CPU usage

* Create a console variable 't_task_pool_worker_max_spin_cycles' this way on platforms with limited power budgets, we can use more efficient methods to wait
* Use OS-Level code to perform our waits, instead of relying on C++ libraries
* Still use the boost queue, so if we are able to pick up a task during the spin lock phase, we can get truly lock free performance 
* Any threads that are spinning should pickup the task, before any threads blocking on a signal, so latency should be lower

* How to structure the OS events though?
* We have our task pool state...

boost::lockfree::queue< std::unique_ptr< TaskInstanceBase > > m_Tasks;
std::atomic< uint32 > m_TaskCount;
WIN32_EVENT m_TaskEvent;

* Then our worker thread state and main thread body..

std::atomic< bool > m_bKill;

------ Thread Body -------
uint32 spinLockCounter = 0;
const uint32 maxSpinLockCycles = 10000;
const float maxSleepLength = 10.f; // in milliseconds

while( m_bKill.load() == false )
{
	// Start popping tasks from the queue
	// As long as the task queue isnt empty, we can keep popping without locks!
	std::unique_ptr< TaskInstanceBase > ptr_task;
	while( taskPool->m_Tasks.pop( ptr_task ) && ptr_task != nullptr )
	{
		// Decrease atmoic task counter
		taskPool->m_TaskCount.fetch_sub( 1, std::memory_order::relaxed );
		
		// Execute task
		// This function should also post the result to the shared state
		// This way, the TaskHandle can be 'waited' on
		// We could also use std::future to see if we get lower latency
		ptr_task->Execute();
		
		// Reset spin lock counter
		spinLockCounter = 0;
	}
	
	// We ran out of work to do.. so lets spin lock for a certain number of cycles
	if( spinLockCounter < maxSpinLockCycles )
	{
		spinLockCounter++;
		_mm_pause(); [better function?]
		continue;
	}
	
	// We spun lock for as long as was allowed, so now, were going to instead resort to an OS-level syncronization function
#ifdef HYPERION_WIN32
	WaitForSingleObject( taskPool->m_TaskEvent, maxSleepLength ); 
	
	// Once a thread gets past the event, we reset it so we can use it again later
	ResetEvent( taskPool->m_TaskEvent );
	
#else
	// Implement something from std:: or boost::
	taskPool->m_TaskEvent.wait_for( ..., std::chrono::milliseconds( maxSleepLength ) );
	
#endif
}


* This should give us lower latency, at the expense of some CPU cycles.
* The final thing we need to worry about, is waiting for tasks to complete and getting results back.
* We could also use OS constructs to do this

struct TaskState
{
#if HYPERION_WIN32
	HANDLE waitHandle;
#else
	std::mutex m;
	std::condition_variable cv;
	bool b;
#endif

	T result;
}


* So, on windows, we can simply set the result in the state, and use WaitForSingleObject to be notified of the task being completed.
* We can also implemenent the OS wait functions for different platforms, and then, if we have to fallback on std:: methods we can

* This really should get us as close to zero latency as physically possible, without just killing performance in the process.
* We can tune the performance as well, by using more spin lock cycles, and lower wait durations, we can get latency down further, but costs CPU time
* Inversely we can lower spin lock cycles (down to zero if desired), and increase the wait duration, which will increase latency at times, but drastically lower CPU usage

* So, this ends up being something we can tune per-platform to get the best mix of performance and power usage from our task scheduling system.
* Then, we can build systems on top of this, to execute a task graph, or something like that..



* How to handle console command changes now?
* Before, we had a system where we could inject callbacks for ConsoleVar changes into a target thread
* Now, we cannot do this, so, we can still make a callback, but, its not garunteed to run on any specific thread or anything.
* Also, console var changes can originate from weird threads, like a UI thread, windows thread, etc...

* But, what we need is, the callback to run in general, but it would be nice for it to run at an expected time.
* For instance, we could have the callback run in the pre-frame phase or something...
* Either way, since there is no way to know what thread a certain entity or system will be on, we can only 




